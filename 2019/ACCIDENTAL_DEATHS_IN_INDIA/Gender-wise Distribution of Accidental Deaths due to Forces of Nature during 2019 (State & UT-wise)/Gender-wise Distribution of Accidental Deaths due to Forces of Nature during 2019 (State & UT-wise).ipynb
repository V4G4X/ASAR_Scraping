{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import ssl\n",
    "import os\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_url = 'https://ncrb.gov.in/sites/default/files/adsi_reports_previous_year/Table-1.8_2019.pdf'\n",
    "fileName = pdf_url[67:]\n",
    "try:\n",
    "    #Delete the file to redownload it\n",
    "    os.remove(fileName)\n",
    "except FileNotFoundError as e:\n",
    "    #Ignore in case FileNotFound Error occurs\n",
    "    pass\n",
    "fileName = wget.download(pdf_url,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import camelot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Table-1.8_2019.pdf'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape on the pages 1-4 as they have the same schema\n",
    "tables = camelot.read_pdf(fileName,\n",
    "                          flavor='stream',\n",
    "                          table_areas=[ \"28.858158319870764,731.4398044986758,567.5437802907917,71.53779676581283\"],\n",
    "                          columns=[\"49.0588691437803,150.06242326332796,188.5399676898223,225.09363489499194,262.60924071082394,292.42933764135705,328.02106623586434,362.6508562197092,393.43289176090474,426.13880452342494,459.8066558966075,494.4364458804524,530.990113085622\"],\n",
    "                          split_text=True,\n",
    "                          pages=\"1-4\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<TableList n=4>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printnAllTables(tables):\n",
    "    for i in range(len(tables)):\n",
    "        print(\"Page No: \",(i+1))\n",
    "        print(tables[i].df)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase we're intersted in seeing the original scraped tables.\n",
    "# Commented as it takes too much screen space\n",
    "# Run if you want\n",
    "# printnAllTables(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes Garbage Rows that may have been detected Before the 'STATES' row\n",
    "# AND\n",
    "# Removes Garbage Rows that may have been detected after the 'TOTAL (ALL INDIA)' row\n",
    "def clean(table):\n",
    "    while(table.df.iloc[0,1] != 'STATES'):\n",
    "        table.df = table.df.iloc[1:]\n",
    "    while(table.df.iloc[-1,1] != 'TOTAL (ALL INDIA)'):\n",
    "        table.df = table.df.iloc[:-1]\n",
    "    # The Return line is unnecessary due to all changes being reflected in the original references\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_table in tables:\n",
    "    clean(each_table)"
   ]
  },
  {
   "source": [
    "# Incase we're intersted in seeing the scraped tables at this point.\n",
    "# Commented as it takes too much screen space\n",
    "# Run if you want\n",
    "# printnAllTables(tables)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# List of Column headers as column are nested, i.e exhibit a multi level/index structure\n",
    "# The multi level structre will be generated and applied in the next \n",
    "column_header = [\n",
    "    [\"Avalanche\",\"Exposure to Cold\",\"Cyclone\"],\n",
    "    [\"Tornado\",\"Tsunami\",\"Earthqauke\"],\n",
    "    [\"Epidemic\",\"Flood\",\"Heat/Sun Stroke\"],\n",
    "    [\"Landslide\",\"Lightning\",\"Torrential Rain\"]\n",
    "]\n",
    "len(column_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_Column(df, title):\n",
    "    column_list = [\n",
    "        (\"Sl. No.\",''),\n",
    "        (\"State/UT\",''), \n",
    "        (title[0],'Male'),\n",
    "        (title[0],'Female'),\n",
    "        (title[0],'Transgender'),\n",
    "        (title[0],'Total'),\n",
    "        (title[1],'Male'),\n",
    "        (title[1],'Female'),\n",
    "        (title[1],'Transgender'),\n",
    "        (title[1],'Total'),\n",
    "        (title[2],'Male'),\n",
    "        (title[2],'Female'),\n",
    "        (title[2],'Transgender'),\n",
    "        (title[2],'Total'),\n",
    "    ]\n",
    "    df.columns = pd.MultiIndex.from_tuples(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tables)):\n",
    "    set_Column(tables[i].df, column_header[i])\n",
    "    tables[i].df.set_index([\"Sl. No.\",\"State/UT\"],inplace=True)"
   ]
  },
  {
   "source": [
    "# Incase we're intersted in seeing the scraped tables at this point.\n",
    "# Commented as it takes too much screen space\n",
    "# Run if you want\n",
    "# printnAllTables(tables)\n",
    "\n",
    "# OR Print a simgle one according to your choice\n",
    "# tables[23].df"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert List of tables to list of DataFrames\n",
    "DataFrames = [each.df.copy() for each in tables]\n",
    "# Concat all the tables one after the other, as they all have the same indexes.\n",
    "final = pd.concat(DataFrames,axis=1)"
   ]
  },
  {
   "source": [
    "#### Uptil page 4 in done <br>Now for Page 5 and Page 6 separately(They have varying schemas)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table5 = camelot.read_pdf(fileName,\n",
    "                          flavor='stream',\n",
    "                          table_areas=[\"32.7059127625202,725.668066821712,537.7236833602585,72.4997530453068\"],\n",
    "                          columns=[\"51.94468497576737,177.95864297253638,227.01751211631665,272.22862681744755,323.21137318255256,363.6127948303716,408.82390953150247,454.0350242326333,492.5125686591277\"],\n",
    "                          split_text=True,\n",
    "                          pages=\"5\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [\"Forest Fire\",\"Causes Other than above\"]\n",
    "column_list = [\n",
    "    (\"Sl. No.\",''),\n",
    "    (\"State/UT\",''), \n",
    "    (title[0],'Male'),\n",
    "    (title[0],'Female'),\n",
    "    (title[0],'Transgender'),\n",
    "    (title[0],'Total'),\n",
    "    (title[1],'Male'),\n",
    "    (title[1],'Female'),\n",
    "    (title[1],'Transgender'),\n",
    "    (title[1],'Total'),\n",
    "]\n",
    "table5[0].df.columns = pd.MultiIndex.from_tuples(column_list)\n",
    "table5[0].df.set_index(['Sl. No.','State/UT'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([final,table5[0].df],axis=1)"
   ]
  },
  {
   "source": [
    "#### Scraping page 6 last"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "table6 = camelot.read_pdf(fileName,\n",
    "                          flavor='stream',\n",
    "                          table_areas=[\"25.972342487883687,712.2006789087965,525.6994507269791,82.11931584024649\"],\n",
    "                          columns=[\"61.56407108239096,214.512310177706,266.4569951534734,325.13525040387725,376.11799676898227,451.1492084006463\"],\n",
    "                          split_text=True,\n",
    "                          pages=\"6\"\n",
    "                         )"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [\"Total\"]\n",
    "column_list = [\n",
    "    (\"Sl. No.\",''),\n",
    "    (\"State/UT\",''), \n",
    "    (title[0],'Male'),\n",
    "    (title[0],'Female'),\n",
    "    (title[0],'Transgender'),\n",
    "    (title[0],'Total'),\n",
    "    (\"Percentage Share\",'')\n",
    "]\n",
    "table6[0].df.columns = pd.MultiIndex.from_tuples(column_list)\n",
    "table6[0].df.set_index(['Sl. No.','State/UT'],inplace=True)"
   ]
  },
  {
   "source": [
    "## Combining final results to export"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([final,table6[0].df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index before saving file, for better formatting in RAW CSV\n",
    "final.reset_index().to_csv(\"Gender-wise Distribution of Accidental Deaths due to Forces of Nature during 2019 (State & UT-wise).csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}