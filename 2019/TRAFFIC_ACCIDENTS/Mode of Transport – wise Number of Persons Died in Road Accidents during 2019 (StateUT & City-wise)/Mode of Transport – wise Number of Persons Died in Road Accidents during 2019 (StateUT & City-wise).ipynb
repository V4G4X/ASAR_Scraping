{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import ssl\n",
    "import os\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter NCRB Individual PDF url\n",
    "pdf_url = 'https://ncrb.gov.in/sites/default/files/adsi_reports_previous_year/Table-1A.4_2019.pdf'\n",
    "fileName = pdf_url[67:]\n",
    "try:\n",
    "    #Delete the file to redownload it\n",
    "    os.remove(fileName)\n",
    "except FileNotFoundError as e:\n",
    "    #Ignore in case FileNotFound Error occurs\n",
    "    pass\n",
    "# Download report\n",
    "fileName = wget.download(pdf_url,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import camelot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Table-1A.4_2019.pdf'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateTables = camelot.read_pdf(fileName,\n",
    "                          flavor='stream',\n",
    "                          table_areas=[\n",
    "                              \"21.643618739903072,734.3256733371578,568.0247495961229,69.61388420682489\"\n",
    "                              ],\n",
    "                          columns=[\n",
    "                              \"49.0588691437803,154.87211631663976,193.3496607431341,238.56077544426498,277.0383198707593,321.2874959612278,359.7650403877222,412.6716639741519,466.540226171244,509.82746365105015\"\n",
    "                              ],\n",
    "                          split_text=True,\n",
    "                          pages=\"1,3,5,7,9\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityTables = camelot.read_pdf(fileName,\n",
    "                          flavor='stream',\n",
    "                          table_areas=[\n",
    "                              \"21.643618739903072,736.2495858961457,569.9486268174476,62.8801902503671\"\n",
    "                              ],\n",
    "                          columns=[\n",
    "                              \"50.982746365105015,161.60568659127628,200.08323101777063,240.4846526655897,278.962197092084,326.0971890145396,369.38442649434575,415.557479806139,464.61634894991926,512.7132794830372\"\n",
    "                              ],\n",
    "                          split_text=True,\n",
    "                          pages=\"2,4,6,8,10\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<TableList n=5>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "stateTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printnAllTables(tables):\n",
    "    for i in range(len(tables)):\n",
    "        print(\"Page No: \",(i+1))\n",
    "        print(tables[i].df)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase we're intersted in seeing the original scraped tables.\n",
    "# Commented as it takes too much screen space\n",
    "# Run if you want\n",
    "# printnAllTables(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes Garbage Rows that may have been detected Before the 'STATES' row\n",
    "# AND\n",
    "# Removes Garbage Rows that may have been detected after the 'TOTAL (ALL INDIA)' row\n",
    "def clean(table):\n",
    "    while(table.df.iloc[0,1] != 'STATES' and table.df.iloc[0,1] != 'AGRA'):\n",
    "        table.df = table.df.iloc[1:]\n",
    "    while(table.df.iloc[-1,1] != 'TOTAL (ALL INDIA)' and table.df.iloc[-1,1] != 'TOTAL (CITIES)'):\n",
    "        table.df = table.df.iloc[:-1]\n",
    "    # The Return line is unnecessary due to all changes being reflected in the original references\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the second column into 1st column index and 2nd column test when faulty/required\n",
    "def split_by_first_space(df, strIndex, stpIndex):\n",
    "    df = df.iloc[strIndex:stpIndex+1]\n",
    "    for index, each in df.iterrows():\n",
    "        space = each[1].find(' ')\n",
    "        each[0] = each[1][:space]\n",
    "        each[1] = each[1][space:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeRows(df, strIndex, stpIndex):\n",
    "    DF = df.loc[strIndex:stpIndex]\n",
    "    df = DF.T\n",
    "    l = []\n",
    "    for index, each in df.iterrows():\n",
    "        output = ''\n",
    "        for ind, cell in each.iteritems():\n",
    "            output += (str(cell) + ' ')\n",
    "#         if(output == ''):\n",
    "#             continue\n",
    "        l.append(output.strip())\n",
    "    l = pd.Series(l,name=str(strIndex))\n",
    "    DF.loc[strIndex] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_table in stateTables:\n",
    "    clean(each_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_table in cityTables:\n",
    "    clean(each_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase we're intersted in seeing the scraped tables at this point.\n",
    "# Commented as it takes too much screen space\n",
    "# Run if you want\n",
    "# printnAllTables(stateTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [each.df.copy() for each in stateTables]\n",
    "cities = [each.df.copy() for each in cityTables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# List of Column headers as column are nested, i.e exhibit a multi level/index structure\n",
    "# The multi level structre will be generated and applied in the next \n",
    "column_header = [\n",
    "    ['Truck/Lorry','Bus','SUV/Station Wagon/etc'],\n",
    "    ['Car','Jeep','Tractor'],\n",
    "    ['Three Wheeler/Auto Rickshaw','Two Wheeler','Other Motor Vehicles'],\n",
    "    ['Bicycle','Hand Drawn Vehicle/Cycle Rickshaw','Animal Drawn Vehicle'],\n",
    "    ['Pedestrian','Others','Grand Total']\n",
    "]\n",
    "len(column_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_Column(df, title, state):\n",
    "    column_list = [\n",
    "        (\"Sl. No.\",''),\n",
    "        (\"State/UT\" if(state) else \"City\",''),\n",
    "        (title[0],'Offenders'),\n",
    "        (title[0],'Victims'),\n",
    "        (title[0],'Total'),\n",
    "        (title[1],'Offenders'),\n",
    "        (title[1],'Victims'),\n",
    "        (title[1],'Total'),\n",
    "        (title[2],'Offenders'),\n",
    "        (title[2],'Victims'),\n",
    "        (title[2],'Total'),\n",
    "    ]\n",
    "    df.columns = pd.MultiIndex.from_tuples(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(state,city) in enumerate(zip(states,cities)):\n",
    "    set_Column(state, column_header[i], True)\n",
    "    state.set_index([\"Sl. No.\",\"State/UT\"],inplace=True)\n",
    "    set_Column(city, column_header[i], False)\n",
    "    city.set_index([\"Sl. No.\",\"City\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Same Index across all tables\n",
    "for each in states:\n",
    "    each.index = states[0].index.copy()\n",
    "for each in cities:\n",
    "    each.index = cities[0].index.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = pd.concat(states, axis=1)\n",
    "City  = pd.concat(cities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase we're intersted in seeing the scraped tables at this point.\n",
    "# Commented as it takes too much screen space\n",
    "# Run if you want\n",
    "# printnAllTables(tables)\n",
    "\n",
    "# OR Print a simgle one according to your choice\n",
    "# tables[23].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index before saving file, for better formatting in RAW CSV\n",
    "State.reset_index().to_csv(\"Mode of Transport â€“ wise Number of Persons Died in Road Accidents during 2019(StateUT-wise).csv\",index=False)\n",
    "City.reset_index().to_csv(\"Mode of Transport â€“ wise Number of Persons Died in Road Accidents during 2019(City-wise).csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}